{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://storage.googleapis.com/ds-publico/IA/loan_default.csv.zip'\n",
    "response = requests.get(url)\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as zip_file:\n",
    "    with zip_file.open('loan_default.csv') as csv_file:\n",
    "        df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Após uma análise dos dados (omitida nesse script) vamos manter apenas algumas das colunas fornecidas, apneas as de maior impacto, pela brevidade do trabalho.\n",
    "\n",
    "keep = ['Status',\n",
    "        'approv_in_adv',\n",
    "        'credit_type',\n",
    "        'loan_purpose',\n",
    "        'age',\n",
    "        'co_applicant_credit_type',\n",
    "        'submission_of_application',\n",
    "        'lump_sum_payment',\n",
    "        'loan_amount',\n",
    "        'income',\n",
    "        'Credit_Score']\n",
    "\n",
    "df_modelo = df[keep]\n",
    "df_modelo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fazendo algumas limpezas finais nos dados\n",
    "\n",
    "# Removendo todos os individuos com renda zero ou nula\n",
    "df_modelo = df_modelo.query(\"income != 0\").dropna(subset=['income'])\n",
    "\n",
    "# Removendo todos os individuos em que loan_purpose é nulo\n",
    "df_modelo = df_modelo.dropna(subset=['loan_purpose'])\n",
    "\n",
    "# Removendo todos os individuos em que approv_in_adv é nulo\n",
    "df_modelo = df_modelo.dropna(subset=['approv_in_adv'])\n",
    "\n",
    "df_modelo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando a variável dependente das explicativas\n",
    "x = df_modelo.drop(columns=['Status'])\n",
    "y = df_modelo['Status']\n",
    "\n",
    "# Transformando as variáveis continuas (menos score) em logaritmo natural (linearização)\n",
    "x['loan_amount'] = np.log(x['loan_amount'])\n",
    "x['income'] = np.log(x['income'])\n",
    "\n",
    "# Transformando as variaveis categoricas em dummies\n",
    "categoricas = ['approv_in_adv',\n",
    "               'credit_type',\n",
    "               'loan_purpose',\n",
    "               'age',\n",
    "               'co_applicant_credit_type',\n",
    "               'submission_of_application',\n",
    "               'lump_sum_payment']\n",
    "\n",
    "x = pd.get_dummies(x, columns=categoricas, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando o df em treino e teste (80/20)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model = LogisticRegression(random_state=42)\n",
    "logistic_model.fit(x_train, y_train)\n",
    "previsoes = logistic_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idenficando a probabilidade otima para corte entre as categorias (roc_curve)\n",
    "# Ponto onde a taxa de falsos positivos é a mais baixa possível, enquanto a taxa de verdadeiros positivos é a mais alta possível\n",
    "\n",
    "probs_train = logistic_model.predict_proba(x_train)\n",
    "fpr, tpr, thresholds = roc_curve(y_train, probs_train[:, 1])\n",
    "distancia = np.sqrt(fpr**2 + (1 - tpr)**2)\n",
    "limiar_otimo = thresholds[np.argmin(distancia)]\n",
    "\n",
    "print(\"Limiar ótimo de probabilidade:\", limiar_otimo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_test = logistic_model.predict_proba(x_test)\n",
    "previsoes = (probs_test[:, 1] >= limiar_otimo).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_confusao = confusion_matrix(y_test, previsoes)\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.heatmap(matriz_confusao, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=logistic_model.classes_,\n",
    "            yticklabels=logistic_model.classes_)\n",
    "plt.xlabel('Previsto')\n",
    "plt.ylabel('Verdadeiro')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_ponderado = f1_score(y_test, previsoes, average='weighted')\n",
    "print(\"F1 Score ponderado:\", f1_ponderado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A probabilidade da classe positiva (status = 1) está na segunda coluna\n",
    "probs_mau_pagador = probs_test[:, 1]\n",
    "\n",
    "# Adicionando as probabilidades ao DataFrame X_train_dummies\n",
    "df_resultado = pd.DataFrame({\n",
    "    'X_test': x_test.index,  # Índice do DataFrame X_test_dummies\n",
    "    'y_test': y_test,  # Valor real\n",
    "    'Probabilidade_estimada': probs_mau_pagador,  # Probabilidade estimada\n",
    "    'Valor_atribuido': previsoes  # Valor atribuído pelo modelo\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
